{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e967d3",
   "metadata": {},
   "source": [
    "# Handwritten Digit recognition \n",
    "## 1. Using CNN classifier \n",
    "### The dataset is loaded by using tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a666f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33da694",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190b6d8",
   "metadata": {},
   "source": [
    "### Splitting MNIST dataset to Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b17d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting MNIST dataset to Train and Test data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9263797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary) #changing image to binary\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    #define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    #plot raw pixel data\n",
    "    plt.imshow(x_train[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740acf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior to the normalization the background is black on top of it the color white is written\n",
    "\n",
    "print(x_train[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a92322",
   "metadata": {},
   "source": [
    "## Pre-processing steps - Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0866540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the image to the values\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20507da0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#after normalization. Here we divided all the values with 255 inorder to have the values in 0 and 1\n",
    "\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbd0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the labels are present in the network\n",
    "\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddbb9b",
   "metadata": {},
   "source": [
    "## Resizing image to make it work on CNN operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f51824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to apply the convolution method we need to resize the image\n",
    "\n",
    "import numpy as np\n",
    "IMG_SIZE = 28\n",
    "x_trainr = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE,1) #increasing kernel(filter) operation by one dimension\n",
    "x_testr = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE,1) #increasing kernel(filter) operation by one dimension\n",
    "print (\"Training samples dimension\", x_trainr.shape)\n",
    "print (\"Testing samples dimension\", x_testr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9bfa71",
   "metadata": {},
   "source": [
    "## Deep Neural Network creation\n",
    "### Training 60,000 samples from MNIST handwritten dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Sequential funtion to set the layers operations in order\n",
    "# importing different layers for the nueral network creration\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e4fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a neural network with 3 convolution layers first\n",
    "\n",
    "CNNmodel = Sequential()\n",
    "\n",
    "# 1st convolution layer\n",
    "CNNmodel.add(Conv2D(64, (3,3), input_shape = x_trainr.shape[1:])) #The input layer size is mentioned only in first convolution layer\n",
    "CNNmodel.add(Activation(\"relu\")) #activation function to make it non linear so that negative values dropped and allowed only >0 values\n",
    "CNNmodel.add(MaxPooling2D(pool_size = (2,2))) #Maxpooling single max value of 2x2 matrix allowed rest is dropped\n",
    "\n",
    "# 2nd convolution layer\n",
    "CNNmodel.add(Conv2D(64, (3,3))) \n",
    "CNNmodel.add(Activation(\"relu\"))\n",
    "CNNmodel.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# 3rd convolution layer\n",
    "#CNNmodel.add(Conv2D(64, (3,3))) \n",
    "#CNNmodel.add(Activation(\"relu\"))\n",
    "#CNNmodel.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# 1st fully connected layer\n",
    "CNNmodel.add (Flatten()) #flattening so the 2D matrix changes to column vector given as input for fully connected layer\n",
    "CNNmodel.add(Dense(64))\n",
    "CNNmodel.add(Activation(\"relu\"))\n",
    "\n",
    "# 2nd fully connected layer\n",
    "CNNmodel.add(Dense(32))\n",
    "CNNmodel.add(Activation(\"relu\"))\n",
    "\n",
    "# Last fully connected layer - output in this layer shall be equal to number of classes i.e 10 (0 to 9)\n",
    "CNNmodel.add(Dense(10)) #notice that the size given here is 10\n",
    "CNNmodel.add(Activation('softmax')) #softmax activation function used for class probabilities\n",
    "             \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing training samples\n",
    "\n",
    "print(\"Total Training Samples = \", len(x_trainr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f63e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b69cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = CNNmodel.fit(x_trainr, y_train,epochs = 5, validation_split = 0.3) #training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843eb944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for finding out the model is performing correctly or not we use predicitiosn simple model for now\n",
    "\n",
    "predictions = CNNmodel.predict([x_testr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6596ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(predictions) # printing predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd64cdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Performing the evaluation on MNIST testing data\n",
    "\n",
    "test_loss, test_acc = CNNmodel.evaluate(x_testr, y_test)\n",
    "print (\"Test loss on 10,000 test samples:\", test_loss)\n",
    "print (\"Validation Accuracy on 10,000 test samples\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy library is used to conver the predictions as they are always in the form of an array due to one hot encoding\n",
    "#argmax here returns the max index value and finds the value of it\n",
    "\n",
    "print (np.argmax(predictions[0])) #checking the zeroth location value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the predictions performed above is true or not\n",
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5113767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.argmax(predictions[128])) #checking the 128th location value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06758c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the predictions performed above is true or not\n",
    "plt.imshow(x_test[128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing openCV library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading wrtitten image in paint\n",
    "paint_img = cv2.imread('zero.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the image to check with respect to axis\n",
    "plt.imshow(paint_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the image size, here we see that there is a color channel\n",
    "\n",
    "paint_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21afedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the image to gray and removing the color channel\n",
    "\n",
    "gray = cv2.cvtColor(paint_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4080e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the size after conversion to gray\n",
    "\n",
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the image size to required model size 28*28\n",
    "\n",
    "resize_img = cv2.resize(gray, (28,28), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8919938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the image size after resizing\n",
    "\n",
    "resize_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the image by diving with 255\n",
    "\n",
    "newimg = tf.keras.utils.normalize(resize_img, axis = 1) #scaling from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ede2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer kernel(filter) operation\n",
    "\n",
    "newimg = np.array(newimg).reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
    "newimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba4e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = CNNmodel.predict(newimg)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0668274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d849d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
